{
    "collab_server" : "",
    "contents" : "################################################################################\n#' Sample Entropy (also known as Kolgomorov-Sinai Entropy)\n#' @description\n#' The Sample Entropy measures the complexity of a time series. Large values of \n#' the Sample Entropy indicate high complexity whereas that smaller values characterize\n#' more regular signals.\n#' @details  The sample entropy is computed using:\n#' \\deqn{h_q(m,r) = log(C_q(m,r)/C_{q}(m+1,r))}{hq(m,r) = log(Cq(m,r)/Cq(m+1,r)),}\n#' where \\emph{m} is the embedding dimension and \\emph{r} is the radius of the neighbourhood. When \n#' computing the correlation dimensions we use the linear regions from the correlation\n#' sums in order to do the estimates. Similarly, the sample entropy \\eqn{h_q(m,r)}{hq(m,r)} \n#' should not change for both various \\emph{m} and \\emph{r}.\n#' @param corrDim.object A \\emph{corrDim} object from which the Sample Entropy\n#' of the time series characterized by \\emph{corrDim} shall be estimated.\n#' @param do.plot do.plot Logical value. If TRUE (default value), a plot of the sample entropy is shown.\n#' @param ... Additional plotting arguments.\n#' @return A \\emph{sampleEntropy} object that contains a list storing the sample entropy (\\emph{sample.entropy}),\n#' the embedding dimensions ( \\emph{embedding.dims}) and radius (\\emph{radius}) for which the sample entropy has \n#' been computed, and the order of the sample entropy (\\emph{entr.order}). The sample entropy\n#' is stored as a matrix in which each row contains the computations for a given embedding dimension and \n#' each column stores the computations for a given radius.\n#' @references H. Kantz  and T. Schreiber: Nonlinear Time series Analysis (Cambridge university press)\n#' @examples\n#' \\dontrun{\n#' x=henon(n.sample = 15000, n.transient = 100, a = 1.4, b = 0.3, \n#'         start = c(0.78,0.8165), do.plot = FALSE)$x\n#' \n#' cd=corrDim(time.series=x,\n#'            min.embedding.dim=2,max.embedding.dim=9,\n#'            corr.order=2,time.lag=1,\n#'            min.radius=0.05,max.radius=1,\n#'            n.points.radius=100,\n#'            theiler.window=20,\n#'            do.plot=TRUE)\n#' \n#' use.col = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \n#'             \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n#' se=sampleEntropy(cd,do.plot=TRUE,col=use.col,\n#'                  type=\"l\",xlim=c(0.1,1),\n#'                  add.legend=T)\n#' se.est = estimate(se,\n#'                   regression.range = c(0.4,0.6),\n#'                   use.embeddings = 6:9,col=use.col,type=\"b\")\n#' print(se.est)\n#' cat(\"Expected K2 = \",0.325,\" Estimated = \",mean(se.est),\"\\n\")\n#' }\n#' @author Constantino A. Garcia\n#' @rdname sampleEntropy\n#' @export sampleEntropy\n#' @exportClass sampleEntropy\nsampleEntropy = function (corrDim.object, do.plot=TRUE,...){ \n  if (!inherits(corrDim.object, \"corrDim\")){\n    stop(\"corrDim.object should be of class corrDim\")\n  }\n  radius = radius(corrDim.object)\n  corr.matrix = corrMatrix(corrDim.object)\n  embeddings = embeddingDims(corrDim.object)\n  number.embeddings = length(embeddings) - 1\n  entropy = matrix(0,nrow= number.embeddings,ncol=length(radius))\n  for (i in 1:number.embeddings){\n    entropy[i,] = log(corr.matrix[i,]/corr.matrix[i+1,])\n  }\n  dimnames(entropy)=list(head(embeddings,-1),radius)\n  sample.entropy = list(sample.entropy = entropy,embedding.dims = head(embeddings,-1),\n                        entr.order=nlOrder(corrDim.object), radius=radius)\n  class(sample.entropy)=\"sampleEntropy\"\n  \n  attr(sample.entropy,\"time.lag\") = attr(corrDim.object,\"time.lag\") \n  attr(sample.entropy,\"id\") = attr(corrDim.object,\"id\") \n  attr(sample.entropy,\"theiler.window\") = attr(corrDim.object,\"theiler.window\") \n  \n  if (do.plot){\n   plot(sample.entropy,...) \n  }\n  \n  return (sample.entropy)\n\n}\n\n#' Returns the sample entropy function \\eqn{h_q(m,r)} used for the computations\n#' of the sample entropy.\n#' @param x A \\emph{sampleEntropy} object.\n#' @return A numeric matrix representing the sample entropy function\n#' \\eqn{h_q(m,r)} obtained in #' the sample entropy computations represented\n#' by the \\emph{sampleEntropy} object.\n#' @seealso \\code{\\link{sampleEntropy}}\n#' @export sampleEntropyFunction\nsampleEntropyFunction = function(x){\n  UseMethod(\"sampleEntropyFunction\")\n}\n\n#' @return The \\emph{sampleEntropyFunction} returns the sample entropy function\n#' \\eqn{h_q(m,r)} used for the computations. The sample\n#' entropy function is represented by a matrix. Each row represents a given\n#' embedding dimension whereas that each column representes a different radius.\n#' @rdname sampleEntropy\n#' @export\nsampleEntropyFunction.sampleEntropy = function(x){\n  return (x$sample.entropy)\n}\n\n#' @return The \\emph{nlOrder} function returns the order of the sample entropy.\n#' @rdname sampleEntropy\n#' @export\nnlOrder.sampleEntropy = function(x){\n  return(x$entr.order)\n}\n\n#' @return The \\emph{radius} function returns the radius on which the sample entropy\n#'  function has been evaluated.\n#' @rdname sampleEntropy\n#' @export\nradius.sampleEntropy = function(x){\n  return (radius.default(x))\n}\n\n#' @return The \\emph{embeddingDims} function returns the embedding dimensions \n#' on which the sample entropy function has been evaluated.\n#' @rdname sampleEntropy\n#' @export\nembeddingDims.sampleEntropy = function(x){\n  return (embeddingDims.default(x))\n}\n\n\n#' @return The \\emph{plot} function shows the graphics for the sample entropy.\n#' @rdname sampleEntropy\n#' @param main A title for the plot.\n#' @param xlab A title for the x axis.\n#' @param ylab A title for the y axis.\n#' @param type Type of plot (see \\code{\\link[graphics]{plot}}).\n#' @param col Vector of colors for each of the dimensions of the plot.\n#' @param pch Vector of symbols for each of the dimensions of the plot\n#' @param ylim Numeric vector of length 2, giving the y coordinates range..\n#' @param add.legend add a legend to the plot?\n#' @export\nplot.sampleEntropy = function(x,main=NULL,xlab=NULL,ylab=NULL,type=\"l\",\n                              col=NULL, pch=NULL, ylim=NULL,add.legend=T,...){\n  if (is.null(xlab)) xlab = expression(\"ln(\"*epsilon*\")\")\n  if (is.null(ylab)) ylab = expression(h[q]*\"(\"*epsilon*\")\")\n  if (is.null(main)) main = \n    bquote(\"Sample entropy (q = \"*.(x$entr.order)*\")    \"*h[.(x$entr.order)]*\"(\"*epsilon*\")\")\n  number.embeddings = length(x$embedding.dims)\n  \n  # obtain vector of graphical parameters if not specified\n  col = vectorizePar(col,number.embeddings)\n  pch = vectorizePar(pch,number.embeddings)\n \n  if (add.legend){\n    current.par =  par(no.readonly = TRUE)\n    on.exit(par(current.par))\n    layout(rbind(1,2), heights=c(8,2))\n  }\n  for (i in 1:number.embeddings){\n     if (i == 1) {\n       if (is.null(ylim)) ylim=range(x$sample.entropy)\n       plot(x$radius,x$sample.entropy[1,],\n            xlab = xlab,ylab = ylab,main=main,type=type,pch=pch[[i]],\n            col=col[[i]],ylim=ylim,...)\n     }else{\n       lines(x$radius,x$sample.entropy[i,],type=type,pch=pch[[i]],\n             col=col[[i]],...)\n     }\n  }\n  if(add.legend){\n    par(mar=c(0, 0, 0, 0))\n    # c(bottom, left, top, right)\n    plot.new()\n    legend(\"center\",\"groups\",ncol=ceiling(number.embeddings/2),\n           col=col,pch=pch,lty=rep(1,number.embeddings),\n           lwd=rep(2.5,number.embeddings),bty=\"n\",\n           legend=x$embedding.dims,title=\"Embedding dimension\")\n  }\n  \n}\n\n\n#' @details For each embedding dimension the sample\n#' entropy is estimated by averaging  \\deqn{h_q(m,r) = log(C_q(m,r)/C_{q}(m+1,r))}{hq(m,r) = log(Cq(m,r)/Cq(m+1,r))}\n#' over the range specified by \\emph{regression range} in the \\emph{estimate} function.\n#' @param x A \\emph{sampleEntropy} object.\n#' @param regression.range Vector with 2 components denoting the range where the function will perform linear regression.\n#' @param use.embeddings A numeric vector specifying which embedding dimensions should the \\emph{estimate} function use to compute\n#' the sample entropy.\n#' @param fit.lty The type of line to plot the regression lines. \n#' @param fit.lwd\tThe width of the line for the regression lines.\n#' @param fit.col A vector of colors to plot the regression lines.\n#' @return The  \\emph{estimate} function returns a vector storing the sample entropy estimate for each embedding dimension.\n#' @rdname sampleEntropy\n#' @export\nestimate.sampleEntropy = function(x,regression.range=NULL,do.plot=TRUE,\n                                  use.embeddings=NULL,fit.col=NULL,\n                                  fit.lty=2, fit.lwd=2,add.legend=T,...){\n  if (is.null(regression.range)){\n    regression.range = range(x$radius)\n  }  \n  if (is.null(use.embeddings)){\n    use.embeddings = x$embedding.dims\n  }\n  #select only embeddings used in the object\n  use.embeddings = intersect(as.numeric(use.embeddings),x$embedding.dims)\n  len.use.embeddings = length(use.embeddings)\n  if(len.use.embeddings<1) {stop(\"The embeddings specified are not present!\\n\")}\n  #range\n  indx = which(x$radius >= regression.range[[1]] & x$radius <=regression.range[[2]])\n    \n  if (len.use.embeddings == 1){\n    sample.entropy.estimate = mean(x$sample.entropy[as.character(use.embeddings),indx])\n  }else{\n    sample.entropy.estimate = apply(x$sample.entropy[as.character(use.embeddings),indx],MARGIN=1,FUN=mean)  \n  }  \n  if (do.plot){\n    #create new sample entropy object with the embedding.dims and radius range used\n    x = list(sample.entropy = x$sample.entropy[as.character(use.embeddings),],\n             embedding.dims = use.embeddings,entr.order=x$entr.order, radius=x$radius)\n    class(x)=\"sampleEntropy\"\n    plotSampleEntropyEstimate(x,sample.entropy.estimate,\n                              fit.col=fit.col,fit.lty=fit.lty,\n                              fit.lwd=fit.lwd,add.legend=add.legend,...)\n  }\n  return(sample.entropy.estimate)\n}\n\nplotSampleEntropyEstimate = function(sampleEntropy.object,\n                                     sample.entropy.estimate,main=NULL,\n                                     xlab=NULL,ylab=NULL,type=\"l\",pch=NULL,\n                                     ylim=NULL,col=NULL,\n                                     fit.col,fit.lty,fit.lwd,\n                                     add.legend=T,...){\n  \n  number.embeddings = length(sampleEntropy.object$embedding.dims)\n  \n  # obtain vector of graphical parameters if not specified\n  col = vectorizePar(col,number.embeddings)\n  pch = vectorizePar(pch,number.embeddings)\n  fit.col = vectorizePar(fit.col,number.embeddings,col)\n  \n  if (add.legend){\n    current.par =  par(no.readonly = TRUE)\n    on.exit(par(current.par))\n    layout(rbind(1,2), heights=c(8,2))\n  }\n  plot(sampleEntropy.object,main=main,\n       xlab=xlab,ylab=ylab,type=type,pch=pch,\n       ylim=ylim,col=col,add.legend=F,...)\n  for (i in 1:number.embeddings){\n    if (i == 1) {\n      abline(h=sample.entropy.estimate[[i]],\n             col=fit.col[[i]],lty=fit.lty,lwd=fit.lwd)\n    }else{\n      abline(h=sample.entropy.estimate[[i]],\n             col=fit.col[[i]],lty=fit.lty,lwd=fit.lwd)\n    }\n  }\n  if(add.legend){\n    par(mar=c(0, 0, 0, 0))\n    # c(bottom, left, top, right)\n    plot.new()\n    legend(\"center\",\"groups\",ncol=ceiling(number.embeddings/2),\n           col=col,pch=pch,lty=rep(1,number.embeddings),\n           lwd=rep(2.5,number.embeddings),bty=\"n\",\n           legend=sampleEntropy.object$embedding.dims,\n           title=\"Embedding dimension\")\n  }\n  \n}\n",
    "created" : 1501179511719.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2028911692",
    "id" : "B377646B",
    "lastKnownWriteTime" : 1496226809,
    "last_content_update" : 1496226809,
    "path" : "~/Code/R/nonlineartseries/R/sampleEntropy.R",
    "project_path" : "R/sampleEntropy.R",
    "properties" : {
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}